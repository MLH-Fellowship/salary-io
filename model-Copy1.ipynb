{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('salaryData.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = pd.DataFrame(data)\n",
    "\n",
    "# columns not used in model\n",
    "columns = ['timestamp', 'otherdetails', 'dmaid', 'rowNumber', \n",
    "            'company', 'cityid',\n",
    "           'level', 'tag', 'bonus', 'basesalary', 'stockgrantvalue'] # TODO: consider adding these to model\n",
    "dataset.drop(columns, inplace=True, axis=1)\n",
    "dataset = dataset.drop_duplicates()\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"totalyearlycompensation\"] = pd.to_numeric(dataset[\"totalyearlycompensation\"])\n",
    "dataset[\"yearsofexperience\"] = pd.to_numeric(dataset[\"yearsofexperience\"])\n",
    "dataset[\"yearsatcompany\"] = pd.to_numeric(dataset[\"yearsatcompany\"])\n",
    "# filter out rows with no gender information\n",
    "dataset = dataset[dataset.gender != \"\"]\n",
    "# get rid of outliers\n",
    "dataset = dataset[dataset[\"totalyearlycompensation\"] < dataset[\"totalyearlycompensation\"].quantile(.96)]\n",
    "# filter out cities with less than 100 datapoints\n",
    "dataset_top_cities = dataset.groupby('location').filter(lambda x: len(x) >= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical data\n",
    "# categorical_cols = ['title', 'location'] \n",
    "\n",
    "# one hot encoding\n",
    "# dataset_encoded = pd.get_dummies(dataset_top_cities, columns = categorical_cols, drop_first = True)\n",
    "# dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# independent and dependent variables\n",
    "features = ['yearsofexperience', 'location', 'title','yearsatcompany', 'gender']\n",
    "target = 'totalyearlycompensation'\n",
    "\n",
    "X = dataset_top_cities[features]\n",
    "Y = dataset_top_cities[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variables to dummy variables\n",
    "X = pd.get_dummies(data=X, drop_first=True)\n",
    "# print(X)\n",
    "\n",
    "# # 80/20 split- 20% training data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model I am using\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training process\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "# get model performance\n",
    "def scores_(model,X,Y):\n",
    "    y_predict = model.predict(X)\n",
    "    rmse = (np.sqrt(mean_squared_error(Y, y_predict)))\n",
    "    r2 = r2_score(Y, y_predict)\n",
    "    print('RMSE is {}'.format(rmse))\n",
    "    print('R2 score is {}'.format(r2))\n",
    "print(\"The model performance of training set\")\n",
    "scores_(model,X_train,Y_train)\n",
    "print(\"--------------------------------------\")\n",
    "print(\"The model performance of testing set\")\n",
    "scores_(model,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the prediction with actual values in test dataset\n",
    "predictions = model.predict(X_test)\n",
    "sns.regplot(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute value for training data\n",
    "data = Y_train\n",
    "predict = model.predict(X_train)\n",
    "training_error = mean_absolute_error(data, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute value for test data\n",
    "test_data = Y_test\n",
    "predict_data = model.predict(X_test)\n",
    "test_data_error = mean_absolute_error(data, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some metric to measure the accuracy of our regression model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# on training data\n",
    "true_value = Y_train\n",
    "predicted_val = model.predict(X_train)\n",
    "accuracy = r2_score(true_value, predicted_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on test data\n",
    "true_value2 = Y_test\n",
    "predicted_val2 = model.predict(X_test)\n",
    "accuracy2 = r2_score(true_value2, predicted_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This model accounts for {}% of the training data with mean data error of {}'.format(round(accuracy2*100,2), round(training_error,2)))\n",
    "print('This model accounts for {}% of the testing data with mean data error of {}'.format(round(accuracy*100,2), round(test_data_error,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}